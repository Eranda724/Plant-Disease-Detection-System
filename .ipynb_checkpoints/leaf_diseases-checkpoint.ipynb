{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "l0IHn9wx054F",
    "outputId": "8bd5d83e-ac36-4b79-9056-92c6c7631fba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow: Machine learning library.\\nmatplotlib.pyplot: Plotting/visualization tool.\\npandas: Data manipulation library.\\nseaborn: Enhanced data visualization.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "'''tensorflow: Machine learning library.\n",
    "matplotlib.pyplot: Plotting/visualization tool.\n",
    "pandas: Data manipulation library.\n",
    "seaborn: Enhanced data visualization.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "pB2tnPkL1-02",
    "outputId": "b73a290b-f4f1-4252-8468-e53a199fced8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#training image preprocessing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m training_set \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m----> 6\u001b[0m     class_names\u001b[38;5;241m=\u001b[39m\u001b[43maa1\u001b[49m,\n\u001b[0;32m      7\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      9\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m     10\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m     interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     follow_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m     crop_to_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m     pad_to_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03mdirectory: Folder with data; if labels are \"inferred\", it must contain class subfolders.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03mlabels: Options are \"inferred\" (from directory), None (no labels), or a custom label list matching files.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mverbose: Show class and file count (default: True).\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aa1' is not defined"
     ]
    }
   ],
   "source": [
    "#training image preprocessing\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "'''\n",
    "directory: Folder with data; if labels are \"inferred\", it must contain class subfolders.\n",
    "labels: Options are \"inferred\" (from directory), None (no labels), or a custom label list matching files.\n",
    "label_mode: Label encoding as \"int\", \"categorical\", \"binary\", or None.\n",
    "class_names: Custom class order (used with inferred labels).\n",
    "color_mode: Image color format - \"grayscale\", \"rgb\", or \"rgba\".\n",
    "batch_size: Data batch size, default is 32; None yields individual samples.\n",
    "image_size: Resized image dimensions, defaults to (256, 256).\n",
    "shuffle: Whether to shuffle data (default: True).\n",
    "seed: Random seed for shuffling.\n",
    "validation_split: Data fraction for validation.\n",
    "subset: \"training\", \"validation\", or \"both\" (used with validation_split).\n",
    "interpolation: Resizing method (e.g., \"bilinear\").\n",
    "follow_links: Follow symbolic links to subdirectories.\n",
    "crop_to_aspect_ratio/pad_to_aspect_ratio: Resize while preserving aspect ratio, with cropping or padding.\n",
    "data_format: \"channel_last\" or \"channel_first\".\n",
    "verbose: Show class and file count (default: True).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation image preprocessing\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=False,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in training_set:\n",
    "    print(x, x.shape) #x content\n",
    "    print(y, y.shape) #y content\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To avoid Overshooding\n",
    "1. Choose small learning rate default 0.001 we are taking 0.0001\n",
    "2. There may be chance of Underfitting so increase number of neurons 0.0001\n",
    "3. Add more convolution layer extract more feature from images there may be possibly that model unable \n",
    "to capture relevent feature or model is confusing due to lack of feature so feed with more feature.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Building Model\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # allows you to build a neural network by stacking layers sequentially, one after another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Building Convolutional Layer1\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25)) #cut layers 25% for reduse overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) #2D - 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1500, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(Dense(units=38, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Adam is an adaptive learning rate optimization algorithm that adjusts the learning rate during training for efficient convergence. It’s widely used due to its speed and performance.\n",
    "#compares the model’s output probabilities with the true labels and computes the error.\n",
    "#calculating the percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set classes:\", training_set.class_names)\n",
    "print(\"Validation set classes:\", validation_set.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "training_history = model.fit(x=training_set, validation_data=validation_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
